{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "datafile = \"/content/drive/MyDrive/University/Courses/CSC311/Project/manual_cleaned_data_universal.csv\""
      ],
      "metadata": {
        "id": "_jCXvf6jEYXs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing:"
      ],
      "metadata": {
        "id": "pio1EywMEGLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer, MinMaxScaler\n",
        "\n",
        "# Load the cleaned data\n",
        "df = pd.read_csv(datafile)\n",
        "\n",
        "# --- Step 0: Identify rows to keep (no NaN in relevant columns) ---\n",
        "# Define all columns used in the model (numerical, MC, text, and label)\n",
        "numerical_cols = [\n",
        "    'Q1: From a scale 1 to 5, how complex is it to make this food? (Where 1 is the most simple, and 5 is the most complex)',\n",
        "    'Q2 Cleaned',\n",
        "    'Q4 Cleaned'\n",
        "]\n",
        "mc_columns = [\n",
        "    'Q3: In what setting would you expect this food to be served? Please check all that apply',\n",
        "    'Q7: When you think about this food item, who does it remind you of?',\n",
        "    'Q8: How much hot sauce would you add to this food item?'\n",
        "]\n",
        "text_columns = ['Q5 Cleaned', 'Q6 Cleaned']\n",
        "label_col = 'Label'\n",
        "\n",
        "# Combine all columns to check for NaN\n",
        "columns_to_check = numerical_cols + mc_columns + text_columns + [label_col]\n",
        "\n",
        "# Identify rows without NaN (keep the original indices)\n",
        "mask = df[columns_to_check].notna().all(axis=1)\n",
        "df_clean = df[mask].copy()  # Keep original indices of non-NaN rows\n",
        "\n",
        "# Extract labels (convert to numpy array)\n",
        "t = df_clean[label_col].to_numpy()\n",
        "\n",
        "# --- Step 1: Normalize Numerical Features ---\n",
        "# Extract numerical features and normalize\n",
        "scaler = MinMaxScaler()\n",
        "X_numerical = scaler.fit_transform(df_clean[numerical_cols])\n",
        "\n",
        "# --- Step 2: One-Hot Encode Multiple-Choice (MC) Columns ---\n",
        "encoded_mc = []\n",
        "for col in mc_columns:\n",
        "    # Split comma-separated answers into lists\n",
        "    split_data = df_clean[col].str.split(',').apply(lambda x: [item.strip() for item in x])\n",
        "\n",
        "    # One-hot encode using MultiLabelBinarizer\n",
        "    mlb = MultiLabelBinarizer()\n",
        "    encoded = mlb.fit_transform(split_data)\n",
        "    encoded_mc.append(encoded)\n",
        "\n",
        "# Combine all MC encoded arrays\n",
        "X_mc = np.hstack(encoded_mc)\n",
        "\n",
        "# --- Step 3: One-Hot Encode Text-Based Columns ---\n",
        "encoded_text = []\n",
        "for col in text_columns:\n",
        "    # Use OneHotEncoder for text responses\n",
        "    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "    encoded = ohe.fit_transform(df_clean[[col]])\n",
        "    encoded_text.append(encoded)\n",
        "\n",
        "# Combine all text encoded arrays\n",
        "X_text = np.hstack(encoded_text)\n",
        "\n",
        "# --- Step 4: Combine All Features into Final Matrix X (as numpy array) ---\n",
        "X = np.hstack([X_numerical, X_mc, X_text])\n",
        "\n",
        "print(X[1,:])\n",
        "#print(t[0])\n",
        "print(f\"Final data matrix X shape: {X.shape}\")\n",
        "print(f\"Labels shape: {t.shape}\")\n",
        "print(f\"Number of rows removed due to NaN: {len(df) - len(df_clean)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Woqr82wzNlwf",
        "outputId": "0c735edd-685a-46ad-f499-1e0a7d1cdfe6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5        0.25       0.20454545 0.         0.         1.\n",
            " 1.         1.         1.         1.         0.         0.\n",
            " 0.         0.         0.         0.         1.         0.\n",
            " 0.         0.         0.         1.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         1.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.        ]\n",
            "Final data matrix X shape: (793, 435)\n",
            "Labels shape: (793,)\n",
            "Number of rows removed due to NaN: 851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-test split:"
      ],
      "metadata": {
        "id": "NIk8MS0qPNPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# First, we will use `train_test_split` to split the data set into\n",
        "# 633 training, and 160 test:\n",
        "X_tv, X_test, t_tv, t_test = train_test_split(X, t, test_size=160/793, random_state=1)"
      ],
      "metadata": {
        "id": "kNEojwGKPQTL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sklearn prediction:"
      ],
      "metadata": {
        "id": "4jWjU65mQsOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "model = QuadraticDiscriminantAnalysis()\n",
        "model.fit(X_tv, t_tv)\n",
        "print(f\"Accuracy: {model.score(X_test, t_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctBxX5deQqij",
        "outputId": "e6fd776f-4c35-451d-8b11-30df68cf4e07"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 2 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}